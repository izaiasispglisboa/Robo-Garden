{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\justino\\.cache\\kagglehub\\datasets\\neuromusic\\avocado-prices\\versions\\1\n",
      "Missing values:\n",
      " Unnamed: 0      0\n",
      "Date            0\n",
      "AveragePrice    0\n",
      "Total Volume    0\n",
      "4046            0\n",
      "4225            0\n",
      "4770            0\n",
      "Total Bags      0\n",
      "Small Bags      0\n",
      "Large Bags      0\n",
      "XLarge Bags     0\n",
      "type            0\n",
      "year            0\n",
      "region          0\n",
      "dtype: int64\n",
      "Best k: 4 with R-squared score: 0.6928581868388315\n",
      "Final R-squared score on test set: 0.6770630559161779\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Download the Dataset\n",
    "import kagglehub\n",
    "\n",
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"neuromusic/avocado-prices\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Step 2: Read the Dataset and Handle Missing Values\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = f\"{path}/avocado.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", data.isnull().sum())\n",
    "\n",
    "# Drop missing values\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Step 3: Feature Selection and Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Drop unnecessary columns\n",
    "X = data.drop(columns=[\"region\", \"Date\", \"AveragePrice\"])\n",
    "y = data[\"AveragePrice\"]\n",
    "\n",
    "# One-hot encode categorical features\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "encoded_features = encoder.fit_transform(X[[\"type\"]])\n",
    "\n",
    "# Drop original categorical columns\n",
    "X = X.drop(columns=[\"type\"])\n",
    "\n",
    "# Scale numerical features\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(X)\n",
    "\n",
    "# Combine scaled numerical features and encoded categorical features\n",
    "import numpy as np\n",
    "X_preprocessed = np.hstack([scaled_features, encoded_features])\n",
    "\n",
    "# Step 4: Split the Data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# First, split off the test set (10%)\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X_preprocessed, y, test_size=0.1, random_state=0)\n",
    "\n",
    "# Then, split the remaining data into training (80%) and validation (10%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.1111, random_state=0)  # 0.1111 of 90% = ~10%\n",
    "\n",
    "# Step 5: Train KNN Regression and Choose Best k\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "best_k = None\n",
    "best_score = float(\"-inf\")\n",
    "\n",
    "# Test different values of k\n",
    "for k in range(1, 21):  # Try k from 1 to 20\n",
    "    model = KNeighborsRegressor(n_neighbors=k)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate on validation set\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    score = r2_score(y_val, y_val_pred)\n",
    "    \n",
    "    if score > best_score:\n",
    "        best_k = k\n",
    "        best_score = score\n",
    "\n",
    "print(f\"Best k: {best_k} with R-squared score: {best_score}\")\n",
    "\n",
    "# Step 6: Evaluate the Final Model on the Test Set\n",
    "# Train the final model\n",
    "final_model = KNeighborsRegressor(n_neighbors=best_k)\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and evaluate on the test set\n",
    "y_test_pred = final_model.predict(X_test)\n",
    "test_score = r2_score(y_test, y_test_pred)\n",
    "\n",
    "print(f\"Final R-squared score on test set: {test_score}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
