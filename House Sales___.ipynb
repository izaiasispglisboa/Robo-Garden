{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justino\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.8).\n",
      "Path to dataset files: C:\\Users\\justino\\.cache\\kagglehub\\datasets\\harlfoxem\\housesalesprediction\\versions\\1\n",
      "Files in dataset directory: ['kc_house_data.csv']\n",
      "Dataset shape: (21613, 21)\n",
      "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
      "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
      "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
      "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
      "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
      "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
      "\n",
      "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
      "0      5650     1.0           0     0  ...      7        1180              0   \n",
      "1      7242     2.0           0     0  ...      7        2170            400   \n",
      "2     10000     1.0           0     0  ...      6         770              0   \n",
      "3      5000     1.0           0     0  ...      7        1050            910   \n",
      "4      8080     1.0           0     0  ...      8        1680              0   \n",
      "\n",
      "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
      "0      1955             0    98178  47.5112 -122.257           1340   \n",
      "1      1951          1991    98125  47.7210 -122.319           1690   \n",
      "2      1933             0    98028  47.7379 -122.233           2720   \n",
      "3      1965             0    98136  47.5208 -122.393           1360   \n",
      "4      1987             0    98074  47.6168 -122.045           1800   \n",
      "\n",
      "   sqft_lot15  \n",
      "0        5650  \n",
      "1        7639  \n",
      "2        8062  \n",
      "3        5000  \n",
      "4        7503  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "Model Comparison:\n",
      "Multiple Linear Regression: R2 = 0.7984901377548106 MSE = 30463598461.55981\n",
      "Polynomial Regression (degree 2): R2 = -8.728729801543898e+16 MSE = 1.3195806735758506e+28\n",
      "KNN Regression (k=5): R2 = 0.8253336381639857 MSE = 26405486324.235123\n",
      "Linear SVR: R2 = 0.10375012867767008 MSE = 135492108907.14061\n",
      "Non-Linear SVR (RBF): R2 = -0.06459461086181562 MSE = 160941913156.4569\n",
      "Decision Tree Regression: R2 = 0.6349276554652029 MSE = 55190436782.67303\n",
      "Random Forest Regression: R2 = 0.7900393059518342 MSE = 31741167429.36945\n",
      "\n",
      "Estimated House Prices for the new sample:\n",
      "Multiple Linear Regression: 385988.27461433783\n",
      "Polynomial Regression: 383212.28125\n",
      "KNN Regression: 411600.0\n",
      "Linear SVR: 440887.22697359335\n",
      "Non-Linear SVR (RBF): 449941.34412086254\n",
      "Decision Tree Regression: 424500.0\n",
      "Random Forest Regression: 428037.5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "\n",
    "path = kagglehub.dataset_download(\"harlfoxem/housesalesprediction\")\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "print(\"Files in dataset directory:\", os.listdir(path))\n",
    "\n",
    "\n",
    "csv_file = os.path.join(path, \"kc_house_data.csv\")\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "# Display basic info about the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())\n",
    "\n",
    "#   - 'sqft_living15' (living room area in SQFT; used here as a proxy)\n",
    "cols = ['price', 'bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'waterfront',\n",
    "        'floors', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'yr_built',\n",
    "        'zipcode', 'sqft_living15']\n",
    "df = df[cols]\n",
    "\n",
    "# Split data into features (X) and target (y)\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Encode categorical data: zipcode (use one-hot encoding)\n",
    "X = pd.get_dummies(X, columns=['zipcode'], drop_first=True)\n",
    "\n",
    "# Split data into training and test sets (20% for testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "# Scale features. For tree-based models\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# Step 3: Build and Train the Models\n",
    "\n",
    "\n",
    "# 3.1 Multiple Linear Regression\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_lin = lin_reg.predict(X_test_scaled)\n",
    "r2_lin = r2_score(y_test, y_pred_lin)\n",
    "mse_lin = mean_squared_error(y_test, y_pred_lin)\n",
    "\n",
    "# 3.2 Polynomial Regression (degree 2)\n",
    "poly_features = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly_features.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly_features.transform(X_test_scaled)\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train)\n",
    "y_pred_poly = poly_reg.predict(X_test_poly)\n",
    "r2_poly = r2_score(y_test, y_pred_poly)\n",
    "mse_poly = mean_squared_error(y_test, y_pred_poly)\n",
    "\n",
    "# 3.3 KNN Regression (using k=5; adjust if needed)\n",
    "knn_reg = KNeighborsRegressor(n_neighbors=5)\n",
    "knn_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_knn = knn_reg.predict(X_test_scaled)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "\n",
    "# 3.4 Linear Support Vector Regression (SVR) with a linear kernel\n",
    "svr_lin = SVR(kernel='linear')\n",
    "svr_lin.fit(X_train_scaled, y_train)\n",
    "y_pred_svr_lin = svr_lin.predict(X_test_scaled)\n",
    "r2_svr_lin = r2_score(y_test, y_pred_svr_lin)\n",
    "mse_svr_lin = mean_squared_error(y_test, y_pred_svr_lin)\n",
    "\n",
    "# 3.5 Non-Linear Support Vector Regression (SVR) with RBF kernel\n",
    "svr_rbf = SVR(kernel='rbf')\n",
    "svr_rbf.fit(X_train_scaled, y_train)\n",
    "y_pred_svr_rbf = svr_rbf.predict(X_test_scaled)\n",
    "r2_svr_rbf = r2_score(y_test, y_pred_svr_rbf)\n",
    "mse_svr_rbf = mean_squared_error(y_test, y_pred_svr_rbf)\n",
    "\n",
    "# 3.6 Decision Tree Regression\n",
    "tree_reg = DecisionTreeRegressor(random_state=42)\n",
    "tree_reg.fit(X_train, y_train)  # Trees work on unscaled data\n",
    "y_pred_tree = tree_reg.predict(X_test)\n",
    "r2_tree = r2_score(y_test, y_pred_tree)\n",
    "mse_tree = mean_squared_error(y_test, y_pred_tree)\n",
    "\n",
    "# 3.7 Random Forest Regression\n",
    "forest_reg = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "forest_reg.fit(X_train, y_train)\n",
    "y_pred_forest = forest_reg.predict(X_test)\n",
    "r2_forest = r2_score(y_test, y_pred_forest)\n",
    "mse_forest = mean_squared_error(y_test, y_pred_forest)\n",
    "\n",
    "\n",
    "# Step 4: Test Models and Compare Results\n",
    "\n",
    "print(\"Model Comparison:\")\n",
    "print(\"Multiple Linear Regression: R2 =\", r2_lin, \"MSE =\", mse_lin)\n",
    "print(\"Polynomial Regression (degree 2): R2 =\", r2_poly, \"MSE =\", mse_poly)\n",
    "print(\"KNN Regression (k=5): R2 =\", r2_knn, \"MSE =\", mse_knn)\n",
    "print(\"Linear SVR: R2 =\", r2_svr_lin, \"MSE =\", mse_svr_lin)\n",
    "print(\"Non-Linear SVR (RBF): R2 =\", r2_svr_rbf, \"MSE =\", mse_svr_rbf)\n",
    "print(\"Decision Tree Regression: R2 =\", r2_tree, \"MSE =\", mse_tree)\n",
    "print(\"Random Forest Regression: R2 =\", r2_forest, \"MSE =\", mse_forest)\n",
    "\n",
    "\n",
    "# Create a dictionary for the new house\n",
    "new_house = {\n",
    "    'bedrooms': 3,\n",
    "    'bathrooms': 2,\n",
    "    'sqft_living': 2000,\n",
    "    'sqft_lot': 5000,\n",
    "    'waterfront': 0,\n",
    "    'floors': 1,\n",
    "    'condition': 3,\n",
    "    'grade': 7,\n",
    "    'sqft_above': 1500,\n",
    "    'sqft_basement': 500,\n",
    "    'yr_built': 1990,\n",
    "    'sqft_living15': 1800\n",
    "}\n",
    "\n",
    "# Add dummy variables for zipcode.\n",
    "# First, get all zipcode dummy column names from the training data.\n",
    "dummy_cols = [col for col in X_train.columns if col.startswith(\"zipcode_\")]\n",
    "# Set all dummy variables to 0 initially.\n",
    "for col in dummy_cols:\n",
    "    new_house[col] = 0\n",
    "\n",
    "# Now, activate the column corresponding to zip code 98028\n",
    "zip_dummy = \"zipcode_\" + \"98028\"\n",
    "if zip_dummy in X_train.columns:\n",
    "    new_house[zip_dummy] = 1\n",
    "\n",
    "# Create a DataFrame for the new sample and ensure the column order matches X_train.\n",
    "new_house_df = pd.DataFrame([new_house])\n",
    "new_house_df = new_house_df[X_train.columns]\n",
    "\n",
    "# For models that require scaled data, transform the new sample.\n",
    "new_house_scaled = scaler.transform(new_house_df)\n",
    "\n",
    "# Estimate house prices using each model.\n",
    "price_lin = lin_reg.predict(new_house_scaled)\n",
    "price_poly = poly_reg.predict(poly_features.transform(new_house_scaled))\n",
    "price_knn = knn_reg.predict(new_house_scaled)\n",
    "price_svr_lin = svr_lin.predict(new_house_scaled)\n",
    "price_svr_rbf = svr_rbf.predict(new_house_scaled)\n",
    "# For tree-based models, use the unscaled new_house_df.\n",
    "price_tree = tree_reg.predict(new_house_df)\n",
    "price_forest = forest_reg.predict(new_house_df)\n",
    "\n",
    "print(\"\\nEstimated House Prices for the new sample:\")\n",
    "print(\"Multiple Linear Regression:\", price_lin[0])\n",
    "print(\"Polynomial Regression:\", price_poly[0])\n",
    "print(\"KNN Regression:\", price_knn[0])\n",
    "print(\"Linear SVR:\", price_svr_lin[0])\n",
    "print(\"Non-Linear SVR (RBF):\", price_svr_rbf[0])\n",
    "print(\"Decision Tree Regression:\", price_tree[0])\n",
    "print(\"Random Forest Regression:\", price_forest[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
